name: AI Test Coverage Pipeline

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]
  workflow_dispatch:

jobs:
  ai_review:
    runs-on: self-hosted   # because Ollama runs locally
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt || true
          pip install pytest requests

      - name: Generate Unit Tests with Ollama
        env:
          BOT: ollama
          LLM_URL: http://localhost:11434/api/generate
          LLM_MODEL: llama3
          SRC_PATH: app.py
          TEST_PATH: tests/test_app_generated.py
        run: |
          python src/github_test_coverage.py

      - name: Run Pytest
        run: pytest tests/ --maxfail=1 --disable-warnings -q
